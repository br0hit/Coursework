{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['age', 'education', 'educationno', 'occupation', 'sex', 'capitalgain',\n",
      "       'capitalloss', 'hoursperweek', 'native', 'Possibility',\n",
      "       'workclass_Federal-gov', 'workclass_Local-gov', 'workclass_Private',\n",
      "       'workclass_Self-emp-inc', 'workclass_Self-emp-not-inc',\n",
      "       'workclass_State-gov', 'workclass_Without-pay',\n",
      "       'maritalstatus_Divorced-Widowed-Abs', 'maritalstatus_Married',\n",
      "       'maritalstatus_Separated-Never-Married', 'relationship_Husband',\n",
      "       'relationship_Not-in-family', 'relationship_Other-relative',\n",
      "       'relationship_Own-child', 'relationship_Unmarried', 'relationship_Wife',\n",
      "       'race_Amer-Indian-Eskimo', 'race_Asian-Pac-Islander', 'race_Black',\n",
      "       'race_Other', 'race_White'],\n",
      "      dtype='object')\n",
      "   age  education  educationno         occupation  sex  capitalgain  \\\n",
      "0   39          6           13       Adm-clerical    1            1   \n",
      "1   50          6           13    Exec-managerial    1            0   \n",
      "2   38          3            9  Handlers-cleaners    1            0   \n",
      "3   53          2            7  Handlers-cleaners    1            0   \n",
      "4   28          6           13     Prof-specialty    0            0   \n",
      "\n",
      "   capitalloss  hoursperweek         native  Possibility  ...  \\\n",
      "0            0            40  United-States            1  ...   \n",
      "1            0            13  United-States            1  ...   \n",
      "2            0            40  United-States            1  ...   \n",
      "3            0            40  United-States            1  ...   \n",
      "4            0            40           Cuba            1  ...   \n",
      "\n",
      "   relationship_Not-in-family  relationship_Other-relative  \\\n",
      "0                           1                            0   \n",
      "1                           0                            0   \n",
      "2                           1                            0   \n",
      "3                           0                            0   \n",
      "4                           0                            0   \n",
      "\n",
      "   relationship_Own-child  relationship_Unmarried  relationship_Wife  \\\n",
      "0                       0                       0                  0   \n",
      "1                       0                       0                  0   \n",
      "2                       0                       0                  0   \n",
      "3                       0                       0                  0   \n",
      "4                       0                       0                  1   \n",
      "\n",
      "   race_Amer-Indian-Eskimo  race_Asian-Pac-Islander  race_Black  race_Other  \\\n",
      "0                        0                        0           0           0   \n",
      "1                        0                        0           0           0   \n",
      "2                        0                        0           0           0   \n",
      "3                        0                        0           1           0   \n",
      "4                        0                        0           1           0   \n",
      "\n",
      "   race_White  \n",
      "0           1  \n",
      "1           1  \n",
      "2           1  \n",
      "3           0  \n",
      "4           0  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# First use the original df to split the data\n",
    "original_df = pd.read_csv('Data.csv')\n",
    "\n",
    "# Drop the rows with missing values\n",
    "original_df = original_df.dropna()\n",
    "\n",
    "# Covnert the float64 columns to int64 in 'hoursperweek'\n",
    "original_df['hoursperweek'] = original_df['hoursperweek'].astype('int64')\n",
    "\n",
    "# Create capitalloss_binary and capitalgain_binary columns by assigning 1 if the value is greater than 0, otherwise 0\n",
    "original_df['capitalloss'] = original_df['capitalloss'].apply(lambda x: 1 if x > 0 else 0)\n",
    "original_df['capitalgain'] = original_df['capitalgain'].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "# Only covert the 'Possibility' column to binary values\n",
    "original_df['Possibility'] = original_df['Possibility'].map({'<=0.5': 1, '>0.5': 0})\n",
    "\n",
    "# Perform binary encoding on the 'sex' column\n",
    "original_df['sex'] = original_df['sex'].map({'Male':1, 'Female':0})\n",
    "\n",
    "# Perform label encoding on the 'education' column\n",
    "original_df['education'] = original_df['education'].map({\n",
    "    'Preschool': 0, \n",
    "    '1st-4th': 1,\n",
    "    '5th-6th': 1,\n",
    "    '7th-8th': 1,\n",
    "    '9th':1,\n",
    "    '10th': 2,\n",
    "    '11th': 2,\n",
    "    '12th': 2,\n",
    "    'HS-grad': 3,\n",
    "    'Some-college': 4,\n",
    "    'Assoc-acdm': 5,\n",
    "    'Assoc-voc': 5,\n",
    "    'Bachelors': 6,\n",
    "    'Masters': 7,\n",
    "    'Doctorate': 8,\n",
    "    'Prof-school': 8})\n",
    "\n",
    "# Define custom categories based on the analysis\n",
    "original_df['maritalstatus'] = original_df['maritalstatus'].map({\n",
    "    'Married-AF-spouse': 'Married',\n",
    "    'Married-civ-spouse': 'Married',\n",
    "    'Divorced': 'Divorced-Widowed-Abs',\n",
    "    'Widowed': 'Divorced-Widowed-Abs',\n",
    "    'Married-spouse-absent': 'Divorced-Widowed-Abs',\n",
    "    'Separated': 'Separated-Never-Married',\n",
    "    'Never-married': 'Separated-Never-Married'\n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "# Conver the categorical columns to one-hot encoding\n",
    "original_df = pd.get_dummies(original_df, columns=['workclass', 'maritalstatus', 'relationship',\n",
    "       'race'])\n",
    "\n",
    "print(original_df.columns)\n",
    "print(original_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import sqrt, pi, exp\n",
    "from collections import defaultdict\n",
    "\n",
    "# Assume `original_df` is already loaded\n",
    "\n",
    "# Define the features and the target variables\n",
    "X = original_df.drop(['Possibility','native','occupation'], axis=1)  \n",
    "y = original_df['Possibility']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "def train_test_split(X, y, test_size=0.2):\n",
    "    # Combining X and y for shuffling and splitting\n",
    "    df_combined = pd.concat([X, y], axis=1)\n",
    "    df_shuffled = df_combined.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    \n",
    "    split_index = int((1 - test_size) * len(df_shuffled))\n",
    "    train_data = df_shuffled[:split_index]\n",
    "    test_data = df_shuffled[split_index:]\n",
    "    \n",
    "    X_train = train_data.drop('Possibility', axis=1)\n",
    "    y_train = train_data['Possibility']\n",
    "    X_test = test_data.drop('Possibility', axis=1)\n",
    "    y_test = test_data['Possibility']\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean and variance for each feature by class\n",
    "def calculate_mean_variance_by_class(X_train, y_train):\n",
    "    summaries = defaultdict(dict)\n",
    "    \n",
    "    # Separate the data by class (0: Innocent, 1: Criminal)\n",
    "    class_labels = np.unique(y_train)\n",
    "    for class_value in class_labels:\n",
    "        X_class = X_train[y_train == class_value]\n",
    "        summaries[class_value] = {\n",
    "            col: (X_class[col].mean(), X_class[col].var()) for col in X_train.columns\n",
    "        }\n",
    "    return summaries\n",
    "\n",
    "# Calculate prior probabilities\n",
    "def calculate_prior_probabilities(y_train):\n",
    "    class_labels, class_counts = np.unique(y_train, return_counts=True)\n",
    "    total_samples = len(y_train)\n",
    "    return {class_value: count / total_samples for class_value, count in zip(class_labels, class_counts)}\n",
    "\n",
    "# Calculate Gaussian Probability Density\n",
    "def gaussian_probability(x, mean, var):\n",
    "    if var == 0:  # To avoid division by zero\n",
    "        var = 1e-4\n",
    "    exponent = exp(-((x - mean)**2 / (2 * var)))\n",
    "    return (1 / sqrt(2 * pi * var)) * exponent\n",
    "\n",
    "# Summarize the training set\n",
    "class_summaries = calculate_mean_variance_by_class(X_train, y_train)\n",
    "priors = calculate_prior_probabilities(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the class probabilities for a given input sample\n",
    "def calculate_class_probabilities(summaries, input_data, priors):\n",
    "    probabilities = {}\n",
    "    \n",
    "    for class_value, class_summary in summaries.items():\n",
    "        probabilities[class_value] = priors[class_value]  # Start with the prior probability\n",
    "        \n",
    "        for feature, value in input_data.items():\n",
    "            mean, var = class_summary[feature]\n",
    "            probabilities[class_value] *= gaussian_probability(value, mean, var)\n",
    "    \n",
    "    return probabilities\n",
    "\n",
    "# Predict class for a single data point\n",
    "def predict(summaries, input_data, priors):\n",
    "    probabilities = calculate_class_probabilities(summaries, input_data, priors)\n",
    "    # Return the class with the highest probability\n",
    "    return max(probabilities, key=probabilities.get)\n",
    "\n",
    "# Predict for the entire test set\n",
    "def predict_all(summaries, X_test, priors):\n",
    "    predictions = []\n",
    "    for _, row in X_test.iterrows():\n",
    "        result = predict(summaries, row, priors)\n",
    "        predictions.append(result)\n",
    "    return np.array(predictions)\n",
    "\n",
    "# Get predictions for the test set\n",
    "y_pred = predict_all(class_summaries, X_test, priors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute precision, recall, and F1 score\n",
    "def precision_recall_f1(y_true, y_pred):\n",
    "    # Convert inputs to numpy arrays for element-wise comparison\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    \n",
    "    # True Positives (TP): Correctly predicted positive instances\n",
    "    TP = np.sum((y_true == 1) & (y_pred == 1))\n",
    "    \n",
    "    # False Positives (FP): Negative instances predicted as positive\n",
    "    FP = np.sum((y_true == 0) & (y_pred == 1))\n",
    "    \n",
    "    # False Negatives (FN): Positive instances predicted as negative\n",
    "    FN = np.sum((y_true == 1) & (y_pred == 0))\n",
    "    \n",
    "    # Precision: TP / (TP + FP)\n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "    \n",
    "    # Recall: TP / (TP + FN)\n",
    "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "    \n",
    "    # F1 Score: 2 * (Precision * Recall) / (Precision + Recall)\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return precision, recall, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.71\n",
      "Precision: 0.94\n",
      "Recall: 0.66\n",
      "F1 Score: 0.78\n"
     ]
    }
   ],
   "source": [
    "# Accuracy calculation\n",
    "def accuracy(y_true, y_pred):\n",
    "    correct = sum(y_true == y_pred)\n",
    "    return correct / len(y_true)\n",
    "\n",
    "# Evaluate accuracy on the test set\n",
    "test_accuracy = accuracy(y_test, y_pred)\n",
    "print(f\"Test Accuracy: {test_accuracy :.2f}\")\n",
    "\n",
    "# Calculate precision, recall, and F1 score on the test set\n",
    "precision, recall, f1 = precision_recall_f1(y_test, y_pred)\n",
    "\n",
    "# Output the results\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (spleeter_env)",
   "language": "python",
   "name": "spleeter_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
