{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "module was compiled against NumPy C-API version 0x10 (NumPy 1.23) but the running NumPy has C-API version 0xf. Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;31mRuntimeError\u001b[0m: module was compiled against NumPy C-API version 0x10 (NumPy 1.23) but the running NumPy has C-API version 0xf. Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import Naive Bayes, SVM, Decision Tree, and KNN from sklearn\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from collections import defaultdict\n",
    "\n",
    "# Import metrics to evaluate the model and also the cross validation\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from math import sqrt, pi, exp\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from collections import Counter\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate prior probabilities\n",
    "def calculate_prior_probabilities(y_train):\n",
    "    class_labels, class_counts = np.unique(y_train, return_counts=True)\n",
    "    total_samples = len(y_train)\n",
    "    return {class_value: count / total_samples for class_value, count in zip(class_labels, class_counts)}\n",
    "\n",
    "# Calculate Gaussian Probability Density\n",
    "def gaussian_probability(x, mean, var):\n",
    "    if var == 0:  # To avoid division by zero\n",
    "        var = 1e-4\n",
    "    exponent = exp(-((x - mean)**2 / (2 * var)))\n",
    "    return (1 / sqrt(2 * pi * var)) * exponent\n",
    "\n",
    "# Calculate the class probabilities for a given input sample\n",
    "def calculate_class_probabilities(summaries, input_data, priors):\n",
    "    probabilities = {}\n",
    "    \n",
    "    for class_value, class_summary in summaries.items():\n",
    "        probabilities[class_value] = priors[class_value]  # Start with the prior probability\n",
    "        \n",
    "        for feature, value in input_data.items():\n",
    "            mean, var = class_summary[feature]\n",
    "            probabilities[class_value] *= gaussian_probability(value, mean, var)\n",
    "    \n",
    "    return probabilities\n",
    "\n",
    "\n",
    "# Predict class for a single data point\n",
    "def predict(summaries, input_data, priors):\n",
    "    probabilities = calculate_class_probabilities(summaries, input_data, priors)\n",
    "    # Return the class with the highest probability\n",
    "    return max(probabilities, key=probabilities.get)\n",
    "\n",
    "# Predict for the entire test set\n",
    "def predict_all(summaries, X_test, priors):\n",
    "    predictions = []\n",
    "    for _, row in X_test.iterrows():\n",
    "        result = predict(summaries, row, priors)\n",
    "        predictions.append(result)\n",
    "    return np.array(predictions)\n",
    "\n",
    "# Accuracy calculation\n",
    "def accuracy(y_true, y_pred):\n",
    "    correct = sum(y_true == y_pred)\n",
    "    return correct / len(y_true)\n",
    "\n",
    "# Calculate the mean and variance for each feature by class\n",
    "def calculate_mean_variance_by_class(X_train, y_train):\n",
    "    summaries = defaultdict(dict)\n",
    "    \n",
    "    # Separate the data by class (0: Innocent, 1: Criminal)\n",
    "    class_labels = np.unique(y_train)\n",
    "    for class_value in class_labels:\n",
    "        X_class = X_train[y_train == class_value]\n",
    "        summaries[class_value] = {\n",
    "            col: (X_class[col].mean(), X_class[col].var()) for col in X_train.columns\n",
    "        }\n",
    "    return summaries\n",
    "\n",
    "# Function to compute precision, recall, and F1 score\n",
    "def precision_recall_f1(y_true, y_pred):\n",
    "    # Convert inputs to numpy arrays for element-wise comparison\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    \n",
    "    # True Positives (TP): Correctly predicted positive instances\n",
    "    TP = np.sum((y_true == 1) & (y_pred == 1))\n",
    "    \n",
    "    # False Positives (FP): Negative instances predicted as positive\n",
    "    FP = np.sum((y_true == 0) & (y_pred == 1))\n",
    "    \n",
    "    # False Negatives (FN): Positive instances predicted as negative\n",
    "    FN = np.sum((y_true == 1) & (y_pred == 0))\n",
    "    \n",
    "    # Precision: TP / (TP + FP)\n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "    \n",
    "    # Recall: TP / (TP + FN)\n",
    "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "    \n",
    "    # F1 Score: 2 * (Precision * Recall) / (Precision + Recall)\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return precision, recall, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 28832 entries, 0 to 30160\n",
      "Data columns (total 23 columns):\n",
      " #   Column                Non-Null Count  Dtype \n",
      "---  ------                --------------  ----- \n",
      " 0   age                   28832 non-null  int64 \n",
      " 1   workclass             28832 non-null  object\n",
      " 2   education             28832 non-null  object\n",
      " 3   educationno           28832 non-null  int64 \n",
      " 4   maritalstatus         28832 non-null  object\n",
      " 5   occupation            28832 non-null  object\n",
      " 6   relationship          28832 non-null  object\n",
      " 7   race                  28832 non-null  object\n",
      " 8   sex                   28832 non-null  int64 \n",
      " 9   capitalgain           28832 non-null  int64 \n",
      " 10  capitalloss           28832 non-null  int64 \n",
      " 11  hoursperweek          28832 non-null  int64 \n",
      " 12  native                28832 non-null  object\n",
      " 13  Possibility           28832 non-null  int64 \n",
      " 14  capitalloss_binary    28832 non-null  int64 \n",
      " 15  capitalgain_binary    28832 non-null  int64 \n",
      " 16  education_label       28832 non-null  int64 \n",
      " 17  native_label          28832 non-null  int64 \n",
      " 18  native_onehot         28832 non-null  object\n",
      " 19  maritalstatus_label   28832 non-null  int64 \n",
      " 20  maritalstatus_onehot  28832 non-null  object\n",
      " 21  relationship_onehot   28832 non-null  object\n",
      " 22  occupation_onehot     28823 non-null  object\n",
      "dtypes: int64(12), object(11)\n",
      "memory usage: 5.3+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Using the new columns, we can now split the data into training and testing sets\n",
    "# Define the features and the target variables\n",
    "\n",
    "# First use the original df to split the data\n",
    "original_df = pd.read_csv('Data.csv')\n",
    "\n",
    "# Drop the rows with missing values\n",
    "original_df = original_df.dropna()\n",
    "\n",
    "# Covnert the float64 columns to int64 in 'hoursperweek'\n",
    "original_df['hoursperweek'] = original_df['hoursperweek'].astype('int64')\n",
    "\n",
    "# Create capitalloss_binary and capitalgain_binary columns by assigning 1 if the value is greater than 0, otherwise 0\n",
    "original_df['capitalloss_binary'] = original_df['capitalloss'].apply(lambda x: 1 if x > 0 else 0)\n",
    "original_df['capitalgain_binary'] = original_df['capitalgain'].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "# Only covert the 'Possibility' column to binary values\n",
    "original_df['Possibility'] = original_df['Possibility'].map({'<=0.5': 1, '>0.5': 0})\n",
    "\n",
    "# Perform binary encoding on the 'sex' column\n",
    "original_df['sex'] = original_df['sex'].map({'Male':1, 'Female':0})\n",
    "\n",
    "# Perform label encoding on the 'education' column\n",
    "original_df['education_label'] = original_df['education'].map({\n",
    "    'Preschool': 0, \n",
    "    '1st-4th': 1,\n",
    "    '5th-6th': 1,\n",
    "    '7th-8th': 1,\n",
    "    '9th':1,\n",
    "    '10th': 2,\n",
    "    '11th': 2,\n",
    "    '12th': 2,\n",
    "    'HS-grad': 3,\n",
    "    'Some-college': 4,\n",
    "    'Assoc-acdm': 5,\n",
    "    'Assoc-voc': 5,\n",
    "    'Bachelors': 6,\n",
    "    'Masters': 7,\n",
    "    'Doctorate': 8,\n",
    "    'Prof-school': 8})\n",
    "\n",
    "original_df['native_label'] = original_df['native'].map({\n",
    "    # 0-5% range\n",
    "    'Dominican-Republic': 0,\n",
    "    'Outlying-US(Guam-USVI-etc)': 0,\n",
    "    'Columbia': 0,\n",
    "    'Guatemala': 0,\n",
    "    \n",
    "    # 5-10% range\n",
    "    'Mexico': 1,\n",
    "\n",
    "    'Nicaragua': 1,\n",
    "    'Peru': 1,\n",
    "    'Vietnam': 1,\n",
    "    'Honduras': 1,\n",
    "    'El-Salvador': 1,\n",
    "    'Haiti': 1,\n",
    "\n",
    "    \n",
    "    # 10-15% range\n",
    "    'Puerto-Rico': 2,\n",
    "    'Trinadad&Tobago': 2,\n",
    "    'Portugal': 2,\n",
    "    'Laos': 2,\n",
    "    'Ecuador': 2,\n",
    "    'Jamaica': 2,\n",
    "\n",
    "    \n",
    "    # 15-20% range\n",
    "    'Thailand': 3,\n",
    "    'Ireland': 3,\n",
    "    'South': 3,\n",
    "    'Scotland': 3,\n",
    "    'Poland': 3,\n",
    "    \n",
    "    # 20-25% range\n",
    "    'Hungary': 4,\n",
    "    'United-States': 4,\n",
    "    \n",
    "    # 25-30% range\n",
    "    'Cuba': 5,\n",
    "    'China': 5,\n",
    "    'Greece': 5,\n",
    "\n",
    "    \n",
    "    # 30-35% range\n",
    "    'Philippines': 6,\n",
    "    'Hong': 6,\n",
    "    'Canada': 6,\n",
    "    'Germany': 6,\n",
    "    'England': 6,\n",
    "    'Italy': 6,\n",
    "    \n",
    "    # 35-40% range\n",
    "    'Yugoslavia': 7,\n",
    "    'Cambodia': 7,\n",
    "    'Japan': 7,\n",
    "    \n",
    "    # 40-45% range\n",
    "    'India': 8,\n",
    "    'Iran': 8,\n",
    "    'France': 8,\n",
    "    'Taiwan': 8\n",
    "})\n",
    "\n",
    "original_df['native_onehot'] = original_df['native'].map({\n",
    "    # 0-5% range\n",
    "    'Dominican-Republic': 0,\n",
    "    'Outlying-US(Guam-USVI-etc)': 0,\n",
    "    'Columbia': 0,\n",
    "    'Guatemala': 0,\n",
    "    \n",
    "    # 5-10% range\n",
    "    'Mexico': 1,\n",
    "\n",
    "    'Nicaragua': 1,\n",
    "    'Peru': 1,\n",
    "    'Vietnam': 1,\n",
    "    'Honduras': 1,\n",
    "    'El-Salvador': 1,\n",
    "    'Haiti': 1,\n",
    "\n",
    "    \n",
    "    # 10-15% range\n",
    "    'Puerto-Rico': 2,\n",
    "    'Trinadad&Tobago': 2,\n",
    "    'Portugal': 2,\n",
    "    'Laos': 2,\n",
    "    'Ecuador': 2,\n",
    "    'Jamaica': 2,\n",
    "\n",
    "    \n",
    "    # 15-20% range\n",
    "    'Thailand': 3,\n",
    "    'Ireland': 3,\n",
    "    'South': 3,\n",
    "    'Scotland': 3,\n",
    "    'Poland': 3,\n",
    "    \n",
    "    # 20-25% range\n",
    "    'Hungary': 4,\n",
    "    'United-States': 4,\n",
    "    \n",
    "    # 25-30% range\n",
    "    'Cuba': 5,\n",
    "    'China': 5,\n",
    "    'Greece': 5,\n",
    "\n",
    "    \n",
    "    # 30-35% range\n",
    "    'Philippines': 6,\n",
    "    'Hong': 6,\n",
    "    'Canada': 6,\n",
    "    'Germany': 6,\n",
    "    'England': 6,\n",
    "    'Italy': 6,\n",
    "    \n",
    "    # 35-40% range\n",
    "    'Yugoslavia': 'Yugoslavia',\n",
    "    'Cambodia': 'Cambodia',\n",
    "    'Japan':  'Japan',\n",
    "    \n",
    "    # 40-45% range\n",
    "    'India': 'India',\n",
    "    'Iran': 'Iran',\n",
    "    'France': 'France',\n",
    "    'Taiwan': 'Taiwan'\n",
    "})\n",
    "\n",
    "# Perform binary encoding on the 'maritalstatus' column\n",
    "original_df['maritalstatus_label'] = original_df['maritalstatus'].map({\n",
    "    'Never-married': 0,\n",
    "    'Divorced': 0,\n",
    "    'Separated': 0,\n",
    "    'Widowed': 0,\n",
    "    'Married-spouse-absent': 0,\n",
    "    'Married-civ-spouse': 1,\n",
    "    'Married-AF-spouse': 1})\n",
    "\n",
    "\n",
    "# Define custom categories based on the analysis\n",
    "original_df['maritalstatus_onehot'] = original_df['maritalstatus'].map({\n",
    "    'Married-AF-spouse': 'Married',\n",
    "    'Married-civ-spouse': 'Married',\n",
    "    'Divorced': 'Divorced-Widowed-Abs',\n",
    "    'Widowed': 'Divorced-Widowed-Abs',\n",
    "    'Married-spouse-absent': 'Divorced-Widowed-Abs',\n",
    "    'Separated': 'Separated-Never-Married',\n",
    "    'Never-married': 'Separated-Never-Married'\n",
    "})\n",
    "\n",
    "# Define custom categories for the relationship column\n",
    "original_df['relationship_onehot'] = original_df['relationship'].map({\n",
    "    'Wife': 'inrelation',\n",
    "    'Husband': 'inrelation',\n",
    "    'Not-in-family': 'Not-in-family',\n",
    "    'Unmarried': 'Unmarried',\n",
    "    'Other-relative': 'Other-relative',\n",
    "    'Own-child': 'Own-child'\n",
    "    })\n",
    "\n",
    "# Define custom categories for the occupation column\n",
    "original_df['occupation_onehot'] = original_df['occupation'].map({\n",
    "    'Exec-managerial': 'Exec-prof',\n",
    "    'Prof-specialty': 'Exec-prof',\n",
    "    'Protective-serv': 'Protective-Tech-Sales',\n",
    "    'Tech-support': 'Protective-Tech-Sales',\n",
    "    'Sales': 'Protective-Tech-Sales',\n",
    "    'Craft-repair': 'Craft-Transp',\n",
    "    'Transport-moving': 'Craft-Transp',\n",
    "    'Adm-clerical': 'Admin-Machine-farm-armed',\n",
    "    'Machine-op-inspct': 'Admin-Machine-farm-armed',\n",
    "    'Farming-fishing': 'Admin-Machine-farm-armed',\n",
    "    'Handlers-cleaners': 'cleaners-others',\n",
    "    'Other-service': 'cleaners-others',\n",
    "    'Priv-house-serv': 'Priv-house-serv',\n",
    "})\n",
    "\n",
    "print(original_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes\n",
      "Accuracy: 0.8194902028784463\n",
      "F1 Score: 0.8753144089112469\n"
     ]
    }
   ],
   "source": [
    "# Use the following features to train the model\n",
    "features_NaiveBayes_numeric = ['age', 'educationno', 'sex', 'capitalgain', 'capitalloss', 'hoursperweek', 'Possibility']\n",
    "features_NaiveBayes_categorical = ['workclass', 'education', 'maritalstatus', 'occupation', 'relationship', 'race', 'native']\n",
    "\n",
    "# Use the following features to train the model\n",
    "features_NaiveBayes = features_NaiveBayes_numeric + features_NaiveBayes_categorical\n",
    "\n",
    "NaiveBayes_df = original_df[features_NaiveBayes]\n",
    "\n",
    "# Conver the categorical columns to one-hot encoding\n",
    "NaiveBayes_df = pd.get_dummies(NaiveBayes_df, columns=features_NaiveBayes_categorical, drop_first=True)\n",
    "\n",
    "# Define the features and the target variables\n",
    "X = NaiveBayes_df.drop(['Possibility'], axis=1)  \n",
    "y = NaiveBayes_df['Possibility']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model using the training sets\n",
    "# Naive Bayes\n",
    "\n",
    "# Create a Gaussian Classifier\n",
    "gnb = GaussianNB()\n",
    "\n",
    "# Train the model using the training sets\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "# Predict the response for test dataset\n",
    "y_pred_NaiveBayes = gnb.predict(X_test)\n",
    "\n",
    "# Find the model accuracy and the F1 score\n",
    "print(\"Naive Bayes\")\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred_NaiveBayes))\n",
    "print(\"F1 Score:\", metrics.f1_score(y_test, y_pred_NaiveBayes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.75\n",
      "Precision: 0.94\n",
      "Recall: 0.71\n",
      "F1 Score: 0.81\n",
      "[0 1 0 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "feautures_NaiveBayes_custom_numeric = ['age', 'educationno', 'sex', 'capitalgain', 'capitalloss_binary', 'hoursperweek', 'Possibility']\n",
    "features_NaiveBayes_custom_categorical = ['workclass', 'education_label', 'maritalstatus', 'occupation_onehot', 'relationship', 'race', 'native_onehot']\n",
    "features_NaiveBayes_custom = feautures_NaiveBayes_custom_numeric + features_NaiveBayes_custom_categorical\n",
    "NaiveBayes_custom_df = original_df[features_NaiveBayes_custom]\n",
    "NaiveBayes_custom_df = pd.get_dummies(NaiveBayes_custom_df, columns=features_NaiveBayes_custom_categorical, drop_first=True)\n",
    "\n",
    "X = NaiveBayes_custom_df.drop(['Possibility'], axis=1)\n",
    "y = NaiveBayes_custom_df['Possibility']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Summarize the training set\n",
    "class_summaries = calculate_mean_variance_by_class(X_train, y_train)\n",
    "priors = calculate_prior_probabilities(y_train)\n",
    "\n",
    "\n",
    "# Get predictions for the test set\n",
    "y_pred_NaiveBayes_custom = predict_all(class_summaries, X_test, priors)\n",
    "\n",
    "# Evaluate accuracy on the test set\n",
    "test_accuracy = accuracy(y_test, y_pred_NaiveBayes_custom)\n",
    "print(f\"Test Accuracy: {test_accuracy :.2f}\")\n",
    "\n",
    "# Calculate precision, recall, and F1 score on the test set\n",
    "precision, recall, f1 = precision_recall_f1(y_test, y_pred_NaiveBayes_custom)\n",
    "\n",
    "# Output the results\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "\n",
    "print(y_pred_NaiveBayes_custom)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 28832 entries, 0 to 30160\n",
      "Data columns (total 54 columns):\n",
      " #   Column                                   Non-Null Count  Dtype\n",
      "---  ------                                   --------------  -----\n",
      " 0   age                                      28832 non-null  int64\n",
      " 1   educationno                              28832 non-null  int64\n",
      " 2   sex                                      28832 non-null  int64\n",
      " 3   capitalgain_binary                       28832 non-null  int64\n",
      " 4   capitalloss_binary                       28832 non-null  int64\n",
      " 5   hoursperweek                             28832 non-null  int64\n",
      " 6   Possibility                              28832 non-null  int64\n",
      " 7   workclass_Local-gov                      28832 non-null  uint8\n",
      " 8   workclass_Private                        28832 non-null  uint8\n",
      " 9   workclass_Self-emp-inc                   28832 non-null  uint8\n",
      " 10  workclass_Self-emp-not-inc               28832 non-null  uint8\n",
      " 11  workclass_State-gov                      28832 non-null  uint8\n",
      " 12  workclass_Without-pay                    28832 non-null  uint8\n",
      " 13  education_label_1                        28832 non-null  uint8\n",
      " 14  education_label_2                        28832 non-null  uint8\n",
      " 15  education_label_3                        28832 non-null  uint8\n",
      " 16  education_label_4                        28832 non-null  uint8\n",
      " 17  education_label_5                        28832 non-null  uint8\n",
      " 18  education_label_6                        28832 non-null  uint8\n",
      " 19  education_label_7                        28832 non-null  uint8\n",
      " 20  education_label_8                        28832 non-null  uint8\n",
      " 21  maritalstatus_Married-AF-spouse          28832 non-null  uint8\n",
      " 22  maritalstatus_Married-civ-spouse         28832 non-null  uint8\n",
      " 23  maritalstatus_Married-spouse-absent      28832 non-null  uint8\n",
      " 24  maritalstatus_Never-married              28832 non-null  uint8\n",
      " 25  maritalstatus_Separated                  28832 non-null  uint8\n",
      " 26  maritalstatus_Widowed                    28832 non-null  uint8\n",
      " 27  occupation_onehot_Craft-Transp           28832 non-null  uint8\n",
      " 28  occupation_onehot_Exec-prof              28832 non-null  uint8\n",
      " 29  occupation_onehot_Priv-house-serv        28832 non-null  uint8\n",
      " 30  occupation_onehot_Protective-Tech-Sales  28832 non-null  uint8\n",
      " 31  occupation_onehot_cleaners-others        28832 non-null  uint8\n",
      " 32  relationship_Not-in-family               28832 non-null  uint8\n",
      " 33  relationship_Other-relative              28832 non-null  uint8\n",
      " 34  relationship_Own-child                   28832 non-null  uint8\n",
      " 35  relationship_Unmarried                   28832 non-null  uint8\n",
      " 36  relationship_Wife                        28832 non-null  uint8\n",
      " 37  race_Asian-Pac-Islander                  28832 non-null  uint8\n",
      " 38  race_Black                               28832 non-null  uint8\n",
      " 39  race_Other                               28832 non-null  uint8\n",
      " 40  race_White                               28832 non-null  uint8\n",
      " 41  native_onehot_1                          28832 non-null  uint8\n",
      " 42  native_onehot_2                          28832 non-null  uint8\n",
      " 43  native_onehot_3                          28832 non-null  uint8\n",
      " 44  native_onehot_4                          28832 non-null  uint8\n",
      " 45  native_onehot_5                          28832 non-null  uint8\n",
      " 46  native_onehot_6                          28832 non-null  uint8\n",
      " 47  native_onehot_Cambodia                   28832 non-null  uint8\n",
      " 48  native_onehot_France                     28832 non-null  uint8\n",
      " 49  native_onehot_India                      28832 non-null  uint8\n",
      " 50  native_onehot_Iran                       28832 non-null  uint8\n",
      " 51  native_onehot_Japan                      28832 non-null  uint8\n",
      " 52  native_onehot_Taiwan                     28832 non-null  uint8\n",
      " 53  native_onehot_Yugoslavia                 28832 non-null  uint8\n",
      "dtypes: int64(7), uint8(47)\n",
      "memory usage: 3.1 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "feautures_custom_numeric = ['age', 'educationno', 'sex', 'capitalgain_binary', 'capitalloss_binary', 'hoursperweek', 'Possibility']\n",
    "features_custom_categorical = ['workclass', 'education_label', 'maritalstatus', 'occupation_onehot', 'relationship', 'race', 'native_onehot']\n",
    "features_custom = feautures_custom_numeric + features_custom_categorical\n",
    "custom_df = original_df[features_custom]\n",
    "custom_df = pd.get_dummies(custom_df, columns=features_custom_categorical, drop_first=True)\n",
    "\n",
    "print(custom_df.info())\n",
    "\n",
    "\n",
    "X = custom_df.drop(['Possibility'], axis=1)\n",
    "y = custom_df['Possibility']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM\n",
      "Accuracy: 0.8368302410265303\n",
      "F1 Score: 0.8942815413998427\n",
      "Decision Tree\n",
      "Accuracy: 0.7841165250563551\n",
      "F1 Score: 0.8546409807355516\n",
      "KNN\n",
      "Accuracy: 0.7872377319230103\n",
      "F1 Score: 0.8585590778097982\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "\n",
    "# Create a SVM Classifier\n",
    "clf = svm.SVC(kernel='linear') # Linear\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred_svm = clf.predict(X_test)\n",
    "\n",
    "print(\"SVM\")\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred_svm))\n",
    "print(\"F1 Score:\", metrics.f1_score(y_test, y_pred_svm))\n",
    "\n",
    "# Decision Tree\n",
    "\n",
    "# Create a Decision Tree Classifier\n",
    "clf = DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "y_pred_dt = clf.predict(X_test)\n",
    "\n",
    "print(\"Decision Tree\")\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred_dt))\n",
    "print(\"F1 Score:\", metrics.f1_score(y_test, y_pred_dt))\n",
    "\n",
    "# KNN\n",
    "\n",
    "# Create a KNN Classifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "neigh.fit(X_train, y_train)\n",
    "y_pred_knn = neigh.predict(X_test)\n",
    "\n",
    "print(\"KNN\")\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred_knn))\n",
    "print(\"F1 Score:\", metrics.f1_score(y_test, y_pred_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\anaconda3\\envs\\env\\lib\\site-packages\\pandas\\core\\arraylike.py:397: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "ename": "UFuncTypeError",
     "evalue": "ufunc 'subtract' did not contain a loop with signature matching types (dtype('<U3'), dtype('float64')) -> None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUFuncTypeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_20676\\625240544.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;31m# Predict and evaluate on the test data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensemble_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[0mf1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'weighted'\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Use 'weighted' for multi-class classification\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_20676\\625240544.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[1;31m# Gather predictions from all models\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m         \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[1;31m# Use majority voting for the final prediction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_20676\\625240544.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[1;31m# Gather predictions from all models\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m         \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[1;31m# Use majority voting for the final prediction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_20676\\625240544.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     24\u001b[0m                 \u001b[0mprob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprior\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m                 \u001b[0mprob\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[1;36m0.5\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpi\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mvar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m                 \u001b[0mprob\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[1;36m0.5\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mvar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m                 \u001b[0mprobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\env\\lib\\site-packages\\pandas\\core\\ops\\common.py\u001b[0m in \u001b[0;36mnew_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[0mother\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mitem_from_zerodim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnew_method\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\env\\lib\\site-packages\\pandas\\core\\arraylike.py\u001b[0m in \u001b[0;36m__rsub__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"__rsub__\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__rsub__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_arith_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroperator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrsub\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"__mul__\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\env\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_arith_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   5637\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_arith_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5638\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malign_method_SERIES\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5639\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mbase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIndexOpsMixin\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_arith_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5641\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\env\\lib\\site-packages\\pandas\\core\\base.py\u001b[0m in \u001b[0;36m_arith_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   1293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1294\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1295\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marithmetic_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1296\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1297\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_construct_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mres_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\env\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py\u001b[0m in \u001b[0;36marithmetic_op\u001b[1;34m(left, right, op)\u001b[0m\n\u001b[0;32m    220\u001b[0m         \u001b[0m_bool_arith_check\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleft\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m         \u001b[0mres_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_na_arithmetic_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    223\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mres_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\env\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py\u001b[0m in \u001b[0;36m_na_arithmetic_op\u001b[1;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_cmp\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mis_object_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mright\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\env\\lib\\site-packages\\pandas\\core\\roperator.py\u001b[0m in \u001b[0;36mrsub\u001b[1;34m(left, right)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mrsub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mright\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mleft\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUFuncTypeError\u001b[0m: ufunc 'subtract' did not contain a loop with signature matching types (dtype('<U3'), dtype('float64')) -> None"
     ]
    }
   ],
   "source": [
    "# Define Custom Naive Bayes Classifier\n",
    "class CustomNaiveBayes:\n",
    "    def fit(self, X, y):\n",
    "        self.classes = np.unique(y)\n",
    "        self.means = {}\n",
    "        self.vars = {}\n",
    "        self.priors = {}\n",
    "        \n",
    "        for cls in self.classes:\n",
    "            X_cls = X[y == cls]\n",
    "            self.means[cls] = X_cls.mean(axis=0)\n",
    "            self.vars[cls] = X_cls.var(axis=0)\n",
    "            self.priors[cls] = X_cls.shape[0] / X.shape[0]\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        for x in X:\n",
    "            probs = []\n",
    "            for cls in self.classes:\n",
    "                mean = self.means[cls]\n",
    "                var = self.vars[cls]\n",
    "                prior = self.priors[cls]\n",
    "                \n",
    "                prob = np.log(prior)\n",
    "                prob -= 0.5 * np.sum(np.log(2 * np.pi * var))\n",
    "                prob -= 0.5 * np.sum(((x - mean) ** 2) / var)\n",
    "                \n",
    "                probs.append(prob)\n",
    "            \n",
    "            predictions.append(self.classes[np.argmax(probs)])\n",
    "        return np.array(predictions)\n",
    "\n",
    "# Initialize classifiers\n",
    "naive_bayes = CustomNaiveBayes()\n",
    "svm_model = svm.SVC(kernel='linear')\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Train the classifiers with imputed data\n",
    "naive_bayes.fit(X_train, y_train)\n",
    "svm_model.fit(X_train, y_train)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Define the Ensemble Classifier\n",
    "class EnsembleClassifier:\n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        for model in self.models:\n",
    "            model.fit(X, y)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # Gather predictions from all models\n",
    "        predictions = np.array([model.predict(X) for model in self.models])\n",
    "        \n",
    "        # Use majority voting for the final prediction\n",
    "        final_predictions = np.apply_along_axis(lambda x: Counter(x).most_common(1)[0][0], axis=0, arr=predictions)\n",
    "        \n",
    "        return final_predictions\n",
    "    \n",
    "\n",
    "\n",
    "# Initialize the ensemble with the classifiers\n",
    "ensemble_model = EnsembleClassifier(models=[naive_bayes, svm_model, decision_tree, knn])\n",
    "\n",
    "# Train the ensemble classifier\n",
    "ensemble_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate on the test data\n",
    "y_pred = ensemble_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')  # Use 'weighted' for multi-class classification\n",
    "\n",
    "print(f\"Ensemble Model Accuracy: {accuracy: }\")\n",
    "print(f\"Ensemble Model F1 Score: {f1: }\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
